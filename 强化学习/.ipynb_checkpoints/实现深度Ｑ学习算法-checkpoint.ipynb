{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHCKzJIfILMkhMktyiMyS/g8CCVF22USrUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea283410b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "observation = env.reset()\n",
    "\n",
    "for i in range(3):\n",
    "    if i > 1:\n",
    "        print(observation.shape)\n",
    "        plt.imshow(observation)\n",
    "        plt.show()\n",
    "\n",
    "    observation, _, _, _ = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    frame = frame[30:200, 10:150]\n",
    "    \n",
    "    frame = frame[::2, ::2, 0]\n",
    "\n",
    "    frame[frame == 144] = 0\n",
    "    frame[frame == 109] = 0\n",
    "\n",
    "    frame[frame != 0] = 1\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 70)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD8CAYAAAAVHWrNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGkkwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea19cd5908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_preprocessed = preprocess_frame(observation)\n",
    "plt.imshow(obs_preprocessed, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent:\n",
    "    def __init__(self, cols, rows, n_actions, batch_size=32):\n",
    "        self.state_size = (cols, rows, 4)\n",
    "        self.n_actions = n_actions\n",
    "        self.epsilon = 1.\n",
    "        self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
    "        self.exploration_steps = 1000000.\n",
    "        self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) / self.exploration_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.discount_factor = 0.99\n",
    "        self.memory = deque(maxlen=400000)\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.optimizer = self.optimizer()\n",
    "        self.avg_q_max, self.avg_loss = 0, 0\n",
    "\n",
    "    def optimizer(self):\n",
    "        a = K.placeholder(shape=(None,), dtype='int32')\n",
    "        y = K.placeholder(shape=(None,), dtype='float32')\n",
    "\n",
    "        py_x = self.model.output\n",
    "\n",
    "        a_one_hot = K.one_hot(a, self.n_actions)\n",
    "        q_value = K.sum(py_x * a_one_hot, axis=1)\n",
    "        error = K.abs(y - q_value)\n",
    "\n",
    "        quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
    "\n",
    "        opt = Adam(lr=0.00025, epsilon=0.01)\n",
    "        updates = opt.get_updates(self.model.trainable_weights, [], loss)\n",
    "        train = K.function([self.model.input, a, y], [loss], updates=updates)\n",
    "\n",
    "        return train\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=self.state_size))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(self.n_actions))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def update_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def action(self, history):\n",
    "        history = np.float32(history / 255.0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_actions)\n",
    "        else:\n",
    "            q_value = self.model.predict(history)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def replay(self, history, action, reward, next_history, dead):\n",
    "        self.memory.append((history, action, reward, next_history, dead))\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        if self.epsilon > self.epsilon_end:\n",
    "            self.epsilon -= self.epsilon_decay_step\n",
    "\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        history = np.zeros((self.batch_size, self.state_size[0], self.state_size[1], self.state_size[2]))\n",
    "        next_history = np.zeros((self.batch_size, self.state_size[0], self.state_size[1], self.state_size[2]))\n",
    "        target = np.zeros((self.batch_size,))\n",
    "        action, reward, dead = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            history[i] = np.float32(mini_batch[i][0] / 255.)\n",
    "            next_history[i] = np.float32(mini_batch[i][3] / 255.)\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            dead.append(mini_batch[i][4])\n",
    "\n",
    "        target_value = self.target_model.predict(next_history)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if dead[i]:\n",
    "                target[i] = reward[i]\n",
    "            else:\n",
    "                target[i] = reward[i] + self.discount_factor * \\\n",
    "                                        np.amax(target_value[i])\n",
    "\n",
    "        loss = self.optimizer([history, action, target])\n",
    "        self.avg_loss += loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 20, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 9, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 7, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               1147392   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,226,915\n",
      "Trainable params: 1,226,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 20, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 9, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 7, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               1147392   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,226,915\n",
      "Trainable params: 1,226,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "\n",
    "n_warmup_steps = 50000\n",
    "update_model_rate = 10000\n",
    "cols, rows = 85, 70\n",
    "n_states = 4\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "agent = DQLAgent(cols, rows, n_actions=3)\n",
    "scores, episodes = [], []\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 38184; score:  1; q 0.103984; loss 0.003715; steps 184\n",
      "episode 38344; score:  1; q 0.104243; loss 0.002910; steps 160\n",
      "episode 38472; score:  0; q 0.103152; loss 0.002797; steps 128\n",
      "episode 38655; score:  2; q 0.096552; loss 0.002553; steps 183\n",
      "episode 38910; score:  3; q 0.107148; loss 0.003168; steps 255\n",
      "episode 39096; score:  1; q 0.104453; loss 0.003673; steps 186\n",
      "episode 39223; score:  0; q 0.105251; loss 0.003306; steps 127\n",
      "episode 39430; score:  2; q 0.107592; loss 0.003523; steps 207\n",
      "episode 39620; score:  2; q 0.097023; loss 0.003680; steps 190\n",
      "episode 39744; score:  0; q 0.105037; loss 0.003634; steps 124\n",
      "episode 39875; score:  0; q 0.105331; loss 0.003324; steps 131\n",
      "episode 40008; score:  0; q 0.104414; loss 0.003160; steps 133\n",
      "episode 40183; score:  1; q 0.118197; loss 0.003377; steps 175\n",
      "episode 40309; score:  0; q 0.113409; loss 0.002717; steps 126\n",
      "episode 40515; score:  2; q 0.122965; loss 0.003545; steps 206\n",
      "episode 40675; score:  1; q 0.115003; loss 0.002720; steps 160\n",
      "episode 40847; score:  1; q 0.119037; loss 0.003700; steps 172\n",
      "episode 40984; score:  0; q 0.116913; loss 0.002727; steps 137\n",
      "episode 41235; score:  3; q 0.118952; loss 0.003652; steps 251\n",
      "episode 41466; score:  2; q 0.119482; loss 0.002895; steps 231\n",
      "episode 41675; score:  2; q 0.125075; loss 0.004085; steps 209\n",
      "episode 41852; score:  1; q 0.120088; loss 0.002639; steps 177\n",
      "episode 42059; score:  2; q 0.121069; loss 0.004048; steps 207\n",
      "episode 42194; score:  0; q 0.117498; loss 0.002537; steps 135\n",
      "episode 42377; score:  1; q 0.122392; loss 0.003650; steps 183\n",
      "episode 42618; score:  2; q 0.124266; loss 0.004375; steps 241\n",
      "episode 42757; score:  0; q 0.121457; loss 0.002688; steps 139\n",
      "episode 42962; score:  2; q 0.123912; loss 0.003782; steps 205\n",
      "episode 43140; score:  1; q 0.124119; loss 0.002798; steps 178\n",
      "episode 43273; score:  0; q 0.124005; loss 0.003970; steps 133\n",
      "episode 43474; score:  2; q 0.119248; loss 0.003018; steps 201\n",
      "episode 43611; score:  0; q 0.122870; loss 0.002840; steps 137\n",
      "episode 43746; score:  0; q 0.124299; loss 0.003224; steps 135\n",
      "episode 43980; score:  3; q 0.125432; loss 0.002661; steps 234\n",
      "episode 44230; score:  3; q 0.126271; loss 0.004037; steps 250\n",
      "episode 44359; score:  0; q 0.125150; loss 0.004569; steps 129\n",
      "episode 44492; score:  0; q 0.126305; loss 0.003623; steps 133\n",
      "episode 44700; score:  2; q 0.123446; loss 0.002766; steps 208\n",
      "episode 45020; score:  4; q 0.128852; loss 0.003014; steps 320\n",
      "episode 45173; score:  1; q 0.128053; loss 0.003956; steps 153\n",
      "episode 45423; score:  3; q 0.127220; loss 0.003790; steps 250\n",
      "episode 45600; score:  1; q 0.127127; loss 0.004034; steps 177\n",
      "episode 45849; score:  3; q 0.131394; loss 0.003743; steps 249\n",
      "episode 46074; score:  2; q 0.135203; loss 0.003243; steps 225\n",
      "episode 46238; score:  1; q 0.123056; loss 0.002279; steps 164\n",
      "episode 46369; score:  0; q 0.127643; loss 0.003087; steps 131\n",
      "episode 46500; score:  0; q 0.127287; loss 0.002262; steps 131\n",
      "episode 46632; score:  0; q 0.128696; loss 0.004001; steps 132\n",
      "episode 46814; score:  1; q 0.131303; loss 0.002992; steps 182\n",
      "episode 46947; score:  0; q 0.128788; loss 0.003735; steps 133\n",
      "episode 47102; score:  1; q 0.128725; loss 0.003113; steps 155\n",
      "episode 47232; score:  0; q 0.129758; loss 0.002992; steps 130\n",
      "episode 47515; score:  4; q 0.117782; loss 0.003129; steps 283\n",
      "episode 47684; score:  1; q 0.132783; loss 0.003400; steps 169\n",
      "episode 47845; score:  1; q 0.130754; loss 0.003284; steps 161\n",
      "episode 47971; score:  0; q 0.134545; loss 0.003454; steps 126\n",
      "episode 48138; score:  1; q 0.134643; loss 0.003074; steps 167\n",
      "episode 48272; score:  0; q 0.135601; loss 0.004285; steps 134\n",
      "episode 48472; score:  2; q 0.129960; loss 0.002647; steps 200\n",
      "episode 48688; score:  2; q 0.134796; loss 0.002235; steps 216\n",
      "episode 48966; score:  3; q 0.136188; loss 0.003243; steps 278\n",
      "episode 49238; score:  3; q 0.138276; loss 0.002691; steps 272\n",
      "episode 49367; score:  0; q 0.133328; loss 0.002056; steps 129\n",
      "episode 49501; score:  0; q 0.132690; loss 0.002444; steps 134\n",
      "episode 49680; score:  1; q 0.135150; loss 0.003041; steps 179\n",
      "episode 49889; score:  2; q 0.140490; loss 0.002756; steps 209\n",
      "episode 50102; score:  2; q 0.136164; loss 0.002778; steps 213\n",
      "episode 50352; score:  3; q 0.147733; loss 0.004037; steps 250\n",
      "episode 50532; score:  1; q 0.145138; loss 0.003536; steps 180\n",
      "episode 50692; score:  1; q 0.141030; loss 0.003013; steps 160\n",
      "episode 50944; score:  3; q 0.144913; loss 0.002718; steps 252\n",
      "episode 51213; score:  3; q 0.153832; loss 0.002660; steps 269\n",
      "episode 51341; score:  0; q 0.147675; loss 0.003041; steps 128\n",
      "episode 51554; score:  2; q 0.149724; loss 0.003140; steps 213\n",
      "episode 51728; score:  1; q 0.146875; loss 0.002682; steps 174\n",
      "episode 51892; score:  1; q 0.149125; loss 0.003602; steps 164\n",
      "episode 52024; score:  0; q 0.149805; loss 0.003416; steps 132\n",
      "episode 52157; score:  0; q 0.145916; loss 0.002924; steps 133\n",
      "episode 52388; score:  3; q 0.138471; loss 0.004227; steps 231\n",
      "episode 52562; score:  1; q 0.153627; loss 0.002506; steps 174\n",
      "episode 52846; score:  3; q 0.153220; loss 0.004047; steps 284\n",
      "episode 52981; score:  0; q 0.151553; loss 0.003570; steps 135\n",
      "episode 53187; score:  2; q 0.149882; loss 0.003696; steps 206\n",
      "episode 53313; score:  0; q 0.151364; loss 0.004309; steps 126\n",
      "episode 53516; score:  2; q 0.151778; loss 0.003901; steps 203\n",
      "episode 53646; score:  0; q 0.154520; loss 0.003230; steps 130\n",
      "episode 53781; score:  0; q 0.153640; loss 0.003111; steps 135\n",
      "episode 53960; score:  1; q 0.154603; loss 0.003732; steps 179\n",
      "episode 54086; score:  0; q 0.154628; loss 0.003210; steps 126\n",
      "episode 54308; score:  2; q 0.154590; loss 0.002596; steps 222\n",
      "episode 54435; score:  0; q 0.154232; loss 0.001841; steps 127\n",
      "episode 54687; score:  3; q 0.156442; loss 0.003270; steps 252\n",
      "episode 54874; score:  2; q 0.155016; loss 0.003411; steps 187\n",
      "episode 55051; score:  1; q 0.162269; loss 0.003946; steps 177\n",
      "episode 55255; score:  2; q 0.159309; loss 0.002822; steps 204\n",
      "episode 55515; score:  3; q 0.157996; loss 0.003585; steps 260\n",
      "episode 55738; score:  3; q 0.144901; loss 0.003001; steps 223\n",
      "episode 55912; score:  1; q 0.159542; loss 0.003219; steps 174\n",
      "episode 56091; score:  1; q 0.157142; loss 0.003043; steps 179\n",
      "episode 56332; score:  3; q 0.159612; loss 0.003418; steps 241\n",
      "episode 56538; score:  2; q 0.161999; loss 0.002949; steps 206\n",
      "episode 56661; score:  0; q 0.156929; loss 0.003162; steps 123\n",
      "episode 56863; score:  2; q 0.160863; loss 0.003229; steps 202\n",
      "episode 57044; score:  1; q 0.163228; loss 0.002665; steps 181\n",
      "episode 57257; score:  2; q 0.162773; loss 0.002634; steps 213\n",
      "episode 57439; score:  1; q 0.166909; loss 0.003674; steps 182\n",
      "episode 57614; score:  1; q 0.166897; loss 0.004257; steps 175\n",
      "episode 57789; score:  1; q 0.165732; loss 0.003200; steps 175\n",
      "episode 58070; score:  4; q 0.161711; loss 0.002769; steps 281\n",
      "episode 58199; score:  0; q 0.164412; loss 0.002535; steps 129\n",
      "episode 58461; score:  4; q 0.165518; loss 0.003797; steps 262\n",
      "episode 58595; score:  0; q 0.165321; loss 0.003136; steps 134\n",
      "episode 58771; score:  1; q 0.165039; loss 0.003006; steps 176\n",
      "episode 59102; score:  5; q 0.168257; loss 0.003290; steps 331\n",
      "episode 59277; score:  1; q 0.168350; loss 0.003377; steps 175\n",
      "episode 59462; score:  1; q 0.168269; loss 0.003195; steps 185\n",
      "episode 59621; score:  1; q 0.166345; loss 0.003034; steps 159\n",
      "episode 59751; score:  0; q 0.173334; loss 0.005479; steps 130\n",
      "episode 59928; score:  1; q 0.172373; loss 0.003519; steps 177\n",
      "episode 60122; score:  1; q 0.175166; loss 0.002570; steps 194\n",
      "episode 60251; score:  0; q 0.175428; loss 0.003253; steps 129\n",
      "episode 60381; score:  0; q 0.176561; loss 0.002755; steps 130\n",
      "episode 60635; score:  3; q 0.173231; loss 0.003850; steps 254\n",
      "episode 60769; score:  0; q 0.180003; loss 0.003822; steps 134\n",
      "episode 60899; score:  0; q 0.176315; loss 0.003231; steps 130\n",
      "episode 61246; score:  5; q 0.178416; loss 0.002602; steps 347\n",
      "episode 61403; score:  1; q 0.176466; loss 0.003463; steps 157\n",
      "episode 61529; score:  0; q 0.177817; loss 0.003330; steps 126\n",
      "episode 61651; score:  0; q 0.176749; loss 0.003190; steps 122\n",
      "episode 61949; score:  4; q 0.186174; loss 0.004427; steps 298\n",
      "episode 62156; score:  2; q 0.182958; loss 0.003157; steps 207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 62359; score:  2; q 0.180672; loss 0.003142; steps 203\n",
      "episode 62532; score:  1; q 0.182324; loss 0.002612; steps 173\n",
      "episode 62699; score:  1; q 0.179419; loss 0.003816; steps 167\n",
      "episode 62951; score:  3; q 0.183398; loss 0.003027; steps 252\n",
      "episode 63079; score:  0; q 0.181263; loss 0.003279; steps 128\n",
      "episode 63263; score:  1; q 0.187231; loss 0.003716; steps 184\n",
      "episode 63398; score:  0; q 0.183893; loss 0.002999; steps 135\n",
      "episode 63641; score:  3; q 0.183360; loss 0.003266; steps 243\n",
      "episode 63829; score:  1; q 0.189162; loss 0.003227; steps 188\n",
      "episode 63986; score:  1; q 0.183909; loss 0.003170; steps 157\n",
      "episode 64188; score:  2; q 0.188075; loss 0.003002; steps 202\n",
      "episode 64350; score:  1; q 0.185364; loss 0.003077; steps 162\n",
      "episode 64563; score:  2; q 0.191257; loss 0.003571; steps 213\n",
      "episode 64742; score:  1; q 0.192604; loss 0.003390; steps 179\n",
      "episode 64998; score:  3; q 0.184840; loss 0.002556; steps 256\n",
      "episode 65142; score:  0; q 0.190612; loss 0.003351; steps 144\n",
      "episode 65410; score:  3; q 0.189560; loss 0.003882; steps 268\n",
      "episode 65534; score:  0; q 0.191773; loss 0.002889; steps 124\n",
      "episode 65696; score:  1; q 0.191897; loss 0.003552; steps 162\n",
      "episode 65888; score:  2; q 0.189759; loss 0.004765; steps 192\n",
      "episode 66045; score:  1; q 0.187389; loss 0.003566; steps 157\n",
      "episode 66260; score:  2; q 0.189836; loss 0.002895; steps 215\n",
      "episode 66592; score:  6; q 0.187017; loss 0.003651; steps 332\n",
      "episode 66797; score:  2; q 0.200377; loss 0.003791; steps 205\n",
      "episode 66927; score:  0; q 0.194081; loss 0.002278; steps 130\n",
      "episode 67138; score:  2; q 0.195327; loss 0.004124; steps 211\n",
      "episode 67305; score:  1; q 0.192552; loss 0.004555; steps 167\n",
      "episode 67510; score:  2; q 0.198956; loss 0.003488; steps 205\n",
      "episode 67784; score:  3; q 0.202302; loss 0.003856; steps 274\n",
      "episode 68011; score:  2; q 0.191262; loss 0.003622; steps 227\n",
      "episode 68393; score:  6; q 0.209019; loss 0.004228; steps 382\n",
      "episode 68647; score:  3; q 0.201239; loss 0.003486; steps 254\n",
      "episode 68848; score:  2; q 0.204338; loss 0.003484; steps 201\n",
      "episode 69028; score:  1; q 0.199573; loss 0.003285; steps 180\n",
      "episode 69162; score:  0; q 0.203050; loss 0.004057; steps 134\n",
      "episode 69368; score:  2; q 0.205090; loss 0.003023; steps 206\n",
      "episode 69575; score:  2; q 0.206247; loss 0.003980; steps 207\n",
      "episode 69795; score:  2; q 0.208154; loss 0.003252; steps 220\n",
      "episode 69970; score:  1; q 0.205513; loss 0.002495; steps 175\n",
      "episode 70186; score:  3; q 0.195815; loss 0.003739; steps 216\n",
      "episode 70434; score:  3; q 0.216140; loss 0.003264; steps 248\n",
      "episode 70676; score:  3; q 0.202253; loss 0.003088; steps 242\n",
      "episode 70815; score:  0; q 0.213700; loss 0.003694; steps 139\n",
      "episode 70942; score:  0; q 0.211322; loss 0.003184; steps 127\n",
      "episode 71211; score:  4; q 0.209330; loss 0.003126; steps 269\n",
      "episode 71364; score:  1; q 0.214016; loss 0.003152; steps 153\n",
      "episode 71700; score:  5; q 0.215279; loss 0.003653; steps 336\n",
      "episode 71923; score:  2; q 0.222009; loss 0.004661; steps 223\n",
      "episode 72123; score:  2; q 0.211631; loss 0.003422; steps 200\n",
      "episode 72252; score:  0; q 0.216027; loss 0.002776; steps 129\n",
      "episode 72378; score:  0; q 0.220522; loss 0.004555; steps 126\n",
      "episode 72524; score:  0; q 0.219562; loss 0.003940; steps 146\n",
      "episode 72699; score:  1; q 0.215649; loss 0.003818; steps 175\n",
      "episode 72860; score:  1; q 0.216926; loss 0.003383; steps 161\n",
      "episode 73091; score:  2; q 0.218918; loss 0.003900; steps 231\n",
      "episode 73223; score:  0; q 0.218856; loss 0.002951; steps 132\n",
      "episode 73427; score:  2; q 0.220390; loss 0.003808; steps 204\n",
      "episode 73560; score:  0; q 0.223913; loss 0.003275; steps 133\n",
      "episode 73692; score:  0; q 0.224223; loss 0.004582; steps 132\n",
      "episode 73855; score:  1; q 0.221208; loss 0.003244; steps 163\n",
      "episode 73993; score:  0; q 0.222366; loss 0.003271; steps 138\n",
      "episode 74168; score:  1; q 0.222556; loss 0.002934; steps 175\n",
      "episode 74356; score:  1; q 0.225185; loss 0.003146; steps 188\n",
      "episode 74534; score:  1; q 0.223835; loss 0.003147; steps 178\n",
      "episode 74662; score:  0; q 0.220463; loss 0.003522; steps 128\n",
      "episode 74864; score:  2; q 0.227381; loss 0.002392; steps 202\n",
      "episode 75084; score:  2; q 0.226588; loss 0.003250; steps 220\n",
      "episode 75262; score:  1; q 0.227989; loss 0.003233; steps 178\n",
      "episode 75437; score:  1; q 0.230677; loss 0.003023; steps 175\n",
      "episode 75649; score:  2; q 0.232167; loss 0.003812; steps 212\n",
      "episode 75855; score:  2; q 0.221077; loss 0.003698; steps 206\n",
      "episode 76083; score:  2; q 0.224098; loss 0.003479; steps 228\n",
      "episode 76257; score:  1; q 0.232705; loss 0.003304; steps 174\n",
      "episode 76517; score:  3; q 0.228469; loss 0.002814; steps 260\n",
      "episode 76725; score:  2; q 0.224876; loss 0.003662; steps 208\n",
      "episode 76942; score:  2; q 0.231846; loss 0.002872; steps 217\n",
      "episode 77117; score:  1; q 0.233296; loss 0.003556; steps 175\n",
      "episode 77249; score:  0; q 0.231257; loss 0.003299; steps 132\n",
      "episode 77491; score:  3; q 0.226396; loss 0.003276; steps 242\n",
      "episode 77622; score:  0; q 0.229767; loss 0.003089; steps 131\n",
      "episode 77780; score:  1; q 0.227516; loss 0.002957; steps 158\n",
      "episode 78002; score:  2; q 0.237284; loss 0.002529; steps 222\n",
      "episode 78128; score:  0; q 0.234565; loss 0.003457; steps 126\n",
      "episode 78342; score:  2; q 0.239184; loss 0.003995; steps 214\n",
      "episode 78551; score:  2; q 0.236790; loss 0.003424; steps 209\n",
      "episode 78712; score:  1; q 0.230210; loss 0.003962; steps 161\n",
      "episode 78870; score:  1; q 0.233211; loss 0.002763; steps 158\n",
      "episode 78996; score:  0; q 0.232854; loss 0.003206; steps 126\n",
      "episode 79127; score:  0; q 0.235247; loss 0.003210; steps 131\n",
      "episode 79256; score:  0; q 0.238403; loss 0.003137; steps 129\n",
      "episode 79387; score:  0; q 0.238316; loss 0.003797; steps 131\n",
      "episode 79595; score:  2; q 0.247612; loss 0.003366; steps 208\n",
      "episode 79730; score:  0; q 0.244999; loss 0.004142; steps 135\n",
      "episode 79937; score:  2; q 0.234080; loss 0.003010; steps 207\n",
      "episode 80145; score:  2; q 0.243153; loss 0.003146; steps 208\n",
      "episode 80351; score:  2; q 0.252805; loss 0.003624; steps 206\n",
      "episode 80527; score:  1; q 0.255990; loss 0.002392; steps 176\n",
      "episode 80741; score:  2; q 0.250928; loss 0.003057; steps 214\n",
      "episode 80964; score:  2; q 0.257595; loss 0.002936; steps 223\n",
      "episode 81163; score:  2; q 0.256317; loss 0.003983; steps 199\n",
      "episode 81351; score:  2; q 0.250725; loss 0.004541; steps 188\n",
      "episode 81479; score:  0; q 0.259337; loss 0.004844; steps 128\n",
      "episode 81647; score:  1; q 0.259296; loss 0.002416; steps 168\n",
      "episode 81854; score:  2; q 0.252837; loss 0.003607; steps 207\n",
      "episode 82026; score:  1; q 0.257470; loss 0.003884; steps 172\n",
      "episode 82205; score:  1; q 0.261648; loss 0.003910; steps 179\n",
      "episode 82383; score:  1; q 0.259818; loss 0.003063; steps 178\n",
      "episode 82509; score:  0; q 0.260190; loss 0.003334; steps 126\n",
      "episode 82662; score:  1; q 0.249613; loss 0.002547; steps 153\n",
      "episode 82866; score:  2; q 0.260559; loss 0.004035; steps 204\n",
      "episode 83001; score:  0; q 0.257046; loss 0.002876; steps 135\n",
      "episode 83261; score:  4; q 0.242522; loss 0.003173; steps 260\n",
      "episode 83439; score:  1; q 0.261459; loss 0.003234; steps 178\n",
      "episode 83731; score:  4; q 0.250772; loss 0.002829; steps 292\n",
      "episode 83938; score:  2; q 0.269778; loss 0.003755; steps 207\n",
      "episode 84104; score:  1; q 0.260880; loss 0.003741; steps 166\n",
      "episode 84294; score:  2; q 0.256769; loss 0.003440; steps 190\n",
      "episode 84429; score:  0; q 0.267156; loss 0.002771; steps 135\n",
      "episode 84619; score:  1; q 0.262822; loss 0.002381; steps 190\n",
      "episode 84748; score:  0; q 0.269398; loss 0.003859; steps 129\n",
      "episode 84934; score:  1; q 0.265295; loss 0.003681; steps 186\n",
      "episode 85069; score:  0; q 0.266424; loss 0.003115; steps 135\n",
      "episode 85196; score:  0; q 0.267169; loss 0.002945; steps 127\n",
      "episode 85352; score:  1; q 0.265328; loss 0.003986; steps 156\n",
      "episode 85568; score:  2; q 0.274181; loss 0.003887; steps 216\n",
      "episode 85751; score:  1; q 0.274744; loss 0.003402; steps 183\n",
      "episode 85917; score:  1; q 0.263862; loss 0.003191; steps 166\n",
      "episode 86051; score:  0; q 0.274363; loss 0.004065; steps 134\n",
      "episode 86189; score:  0; q 0.273919; loss 0.004170; steps 138\n",
      "episode 86351; score:  1; q 0.265231; loss 0.003070; steps 162\n",
      "episode 86507; score:  1; q 0.264476; loss 0.003092; steps 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 86636; score:  0; q 0.272953; loss 0.002659; steps 129\n",
      "episode 86885; score:  3; q 0.278167; loss 0.003685; steps 249\n",
      "episode 87177; score:  3; q 0.274800; loss 0.003730; steps 292\n",
      "episode 87311; score:  0; q 0.274315; loss 0.002907; steps 134\n",
      "episode 87448; score:  0; q 0.276048; loss 0.002846; steps 137\n",
      "episode 87580; score:  0; q 0.275022; loss 0.004354; steps 132\n",
      "episode 87735; score:  1; q 0.279772; loss 0.003910; steps 155\n",
      "episode 87912; score:  1; q 0.282146; loss 0.002903; steps 177\n",
      "episode 88126; score:  2; q 0.279852; loss 0.003777; steps 214\n",
      "episode 88305; score:  1; q 0.276299; loss 0.003047; steps 179\n",
      "episode 88440; score:  0; q 0.280466; loss 0.003915; steps 135\n",
      "episode 88674; score:  2; q 0.284861; loss 0.003657; steps 234\n",
      "episode 88863; score:  1; q 0.276750; loss 0.003617; steps 189\n",
      "episode 89052; score:  2; q 0.265429; loss 0.002885; steps 189\n",
      "episode 89254; score:  2; q 0.280308; loss 0.002779; steps 202\n",
      "episode 89468; score:  2; q 0.284689; loss 0.003416; steps 214\n",
      "episode 89625; score:  1; q 0.277128; loss 0.003762; steps 157\n",
      "episode 89783; score:  1; q 0.276882; loss 0.004129; steps 158\n",
      "episode 89914; score:  0; q 0.286552; loss 0.004034; steps 131\n",
      "episode 90071; score:  1; q 0.286844; loss 0.003967; steps 157\n",
      "episode 90244; score:  1; q 0.302519; loss 0.002614; steps 173\n",
      "episode 90416; score:  1; q 0.307283; loss 0.003892; steps 172\n",
      "episode 90657; score:  3; q 0.287281; loss 0.003041; steps 241\n",
      "episode 90787; score:  0; q 0.303749; loss 0.004183; steps 130\n",
      "episode 90944; score:  1; q 0.297542; loss 0.002978; steps 157\n",
      "episode 91147; score:  2; q 0.294954; loss 0.003451; steps 203\n",
      "episode 91277; score:  0; q 0.305959; loss 0.002639; steps 130\n",
      "episode 91461; score:  1; q 0.305647; loss 0.004220; steps 184\n",
      "episode 91642; score:  1; q 0.308959; loss 0.003355; steps 181\n",
      "episode 91788; score:  0; q 0.309473; loss 0.003517; steps 146\n",
      "episode 91913; score:  0; q 0.306916; loss 0.002867; steps 125\n",
      "episode 92094; score:  1; q 0.310705; loss 0.004123; steps 181\n",
      "episode 92230; score:  0; q 0.306812; loss 0.003207; steps 136\n",
      "episode 92389; score:  1; q 0.304202; loss 0.003038; steps 159\n",
      "episode 92661; score:  3; q 0.316556; loss 0.003944; steps 272\n",
      "episode 92889; score:  2; q 0.319104; loss 0.003888; steps 228\n",
      "episode 93067; score:  1; q 0.316402; loss 0.003845; steps 178\n",
      "episode 93303; score:  2; q 0.318574; loss 0.003890; steps 236\n",
      "episode 93438; score:  0; q 0.319792; loss 0.005055; steps 135\n",
      "episode 93626; score:  2; q 0.301661; loss 0.004464; steps 188\n",
      "episode 93796; score:  1; q 0.313943; loss 0.003297; steps 170\n",
      "episode 93926; score:  0; q 0.313800; loss 0.002401; steps 130\n",
      "episode 94194; score:  3; q 0.303818; loss 0.003487; steps 268\n",
      "episode 94398; score:  2; q 0.318820; loss 0.002826; steps 204\n",
      "episode 94635; score:  3; q 0.297810; loss 0.002635; steps 237\n",
      "episode 94891; score:  3; q 0.322741; loss 0.003587; steps 256\n",
      "episode 95067; score:  1; q 0.330623; loss 0.004395; steps 176\n",
      "episode 95259; score:  2; q 0.306187; loss 0.003163; steps 192\n",
      "episode 95515; score:  3; q 0.314823; loss 0.003886; steps 256\n",
      "episode 95645; score:  0; q 0.323064; loss 0.003830; steps 130\n",
      "episode 95816; score:  1; q 0.322926; loss 0.003908; steps 171\n",
      "episode 95972; score:  1; q 0.323357; loss 0.004283; steps 156\n",
      "episode 96153; score:  2; q 0.318285; loss 0.003013; steps 181\n",
      "episode 96356; score:  2; q 0.325694; loss 0.003830; steps 203\n",
      "episode 96560; score:  2; q 0.323164; loss 0.002675; steps 204\n",
      "episode 96689; score:  0; q 0.322307; loss 0.002178; steps 129\n",
      "episode 96816; score:  0; q 0.321558; loss 0.003309; steps 127\n",
      "episode 96955; score:  0; q 0.326533; loss 0.003469; steps 139\n",
      "episode 97091; score:  0; q 0.329165; loss 0.004343; steps 136\n",
      "episode 97253; score:  1; q 0.322646; loss 0.002888; steps 162\n",
      "episode 97392; score:  0; q 0.325930; loss 0.003475; steps 139\n",
      "episode 97629; score:  3; q 0.323855; loss 0.002960; steps 237\n",
      "episode 97894; score:  3; q 0.336317; loss 0.004221; steps 265\n",
      "episode 98190; score:  5; q 0.315419; loss 0.003576; steps 296\n",
      "episode 98316; score:  0; q 0.331375; loss 0.002846; steps 126\n",
      "episode 98543; score:  2; q 0.337723; loss 0.004448; steps 227\n",
      "episode 98767; score:  2; q 0.334508; loss 0.003129; steps 224\n",
      "episode 98901; score:  0; q 0.333522; loss 0.002910; steps 134\n",
      "episode 99035; score:  0; q 0.331224; loss 0.003366; steps 134\n",
      "episode 99270; score:  2; q 0.331615; loss 0.003841; steps 235\n",
      "episode 99401; score:  0; q 0.334006; loss 0.004503; steps 131\n",
      "episode 99603; score:  2; q 0.336015; loss 0.003006; steps 202\n",
      "episode 99736; score:  0; q 0.335730; loss 0.003513; steps 133\n",
      "episode 99941; score:  2; q 0.332420; loss 0.003949; steps 205\n",
      "episode 100172; score:  2; q 0.345939; loss 0.002901; steps 231\n",
      "episode 100420; score:  3; q 0.354464; loss 0.004075; steps 248\n",
      "episode 100558; score:  0; q 0.353134; loss 0.004169; steps 138\n",
      "episode 100728; score:  1; q 0.357446; loss 0.002665; steps 170\n",
      "episode 100912; score:  1; q 0.361919; loss 0.004053; steps 184\n",
      "episode 101246; score:  4; q 0.361112; loss 0.003408; steps 334\n",
      "episode 101422; score:  1; q 0.367580; loss 0.004067; steps 176\n",
      "episode 101686; score:  3; q 0.361148; loss 0.003303; steps 264\n",
      "episode 101921; score:  3; q 0.345444; loss 0.002590; steps 235\n",
      "episode 102104; score:  1; q 0.362216; loss 0.003908; steps 183\n",
      "episode 102277; score:  1; q 0.363758; loss 0.003332; steps 173\n",
      "episode 102407; score:  0; q 0.361636; loss 0.002880; steps 130\n",
      "episode 102583; score:  1; q 0.359137; loss 0.004245; steps 176\n",
      "episode 102722; score:  0; q 0.361693; loss 0.003696; steps 139\n",
      "episode 102855; score:  0; q 0.362121; loss 0.004211; steps 133\n",
      "episode 102986; score:  0; q 0.363854; loss 0.003452; steps 131\n",
      "episode 103218; score:  3; q 0.365398; loss 0.002754; steps 232\n",
      "episode 103482; score:  3; q 0.353948; loss 0.003713; steps 264\n",
      "episode 103641; score:  1; q 0.363532; loss 0.004105; steps 159\n",
      "episode 103828; score:  1; q 0.372667; loss 0.003824; steps 187\n",
      "episode 104073; score:  3; q 0.358058; loss 0.003809; steps 245\n",
      "episode 104202; score:  0; q 0.369397; loss 0.003865; steps 129\n",
      "episode 104424; score:  2; q 0.370126; loss 0.004135; steps 222\n",
      "episode 104635; score:  2; q 0.358096; loss 0.002516; steps 211\n",
      "episode 104866; score:  3; q 0.358783; loss 0.003170; steps 231\n",
      "episode 104998; score:  0; q 0.371670; loss 0.003535; steps 132\n",
      "episode 105162; score:  1; q 0.363817; loss 0.003324; steps 164\n",
      "episode 105340; score:  1; q 0.371478; loss 0.003149; steps 178\n",
      "episode 105517; score:  1; q 0.373686; loss 0.003868; steps 177\n",
      "episode 105769; score:  3; q 0.365841; loss 0.004016; steps 252\n",
      "episode 105987; score:  2; q 0.374225; loss 0.003502; steps 218\n",
      "episode 106158; score:  1; q 0.376511; loss 0.004279; steps 171\n",
      "episode 106333; score:  1; q 0.381670; loss 0.003031; steps 175\n",
      "episode 106467; score:  0; q 0.374253; loss 0.003024; steps 134\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    done = False\n",
    "    dead = False\n",
    "    step, score, start_life = 0, 0, 5\n",
    "    observation = env.reset()\n",
    "\n",
    "\n",
    "    state = preprocess_frame(observation, cols, rows)\n",
    "    history = np.stack((state, state, state, state), axis=2)\n",
    "    history = np.reshape([history], (1, cols, rows, n_states))\n",
    "\n",
    "    while not done:\n",
    "        n_steps += 1\n",
    "        step += 1\n",
    "        \n",
    "     \n",
    "        action = agent.action(history)\n",
    "        observation, reward, done, info = env.step(action+1)\n",
    "        \n",
    "        state_next = preprocess_frame(observation, cols, rows)\n",
    "        state_next = np.reshape([state_next], (1, cols, rows, 1))\n",
    "        history_next = np.append(state_next, history[:, :, :, :3], axis=3)\n",
    "\n",
    "        agent.avg_q_max += np.amax(agent.model.predict(history)[0])\n",
    "        reward = np.clip(reward, -1., 1.)\n",
    "\n",
    "        agent.replay(history, action, reward, history_next, dead)\n",
    "        agent.train()\n",
    "        if n_steps % update_model_rate == 0:\n",
    "            agent.update_model()\n",
    "        score += reward\n",
    "\n",
    "        if dead:\n",
    "            dead = False\n",
    "        else:\n",
    "            history = history_next\n",
    "\n",
    "        if done:\n",
    "            print('episode {:2d}; score: {:2.0f}; q {:2f}; loss {:2f}; steps {}'\n",
    "                  .format(n_steps, score, agent.avg_q_max / float(step), agent.avg_loss / float(step), step))\n",
    "\n",
    "            agent.avg_q_max, agent.avg_loss = 0, 0\n",
    "    \n",
    "    if n_steps % 1000 == 0:\n",
    "        agent.model.save_weights(\"breakout_dql.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "agent = DQLAgent(cols, rows, n_action=3)\n",
    "\n",
    "for i in range(5):\n",
    "    observation = env.reset()\n",
    "\n",
    "    state = pre_processing(observation, cols, rows)\n",
    "    history = np.stack((state, state, state, state), axis=2)\n",
    "    history = np.reshape([history], (1, cols, rows, n_states))\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.get_action(history)\n",
    "        observe, reward, done, info = env.step(action+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
