{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据下载 https://github.com/harvardnlp/sent-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_filename = 'Data/sumdata/train/train.article.txt'\n",
    "title_filename = 'Data/sumdata/train/train.title.txt'\n",
    "\n",
    "with open(article_filename) as article_file:\n",
    "    articles = article_file.readlines()\n",
    "with open(title_filename) as title_file:\n",
    "    titles = title_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "    vocab = set(text.split())\n",
    "    vocab_to_int = {'<S>': 0, '<E>': 1, '<UNK>': 2, '<PAD>': 3 }\n",
    "\n",
    "    for i, v in enumerate(vocab, len(vocab_to_int)):\n",
    "        vocab_to_int[v] = i\n",
    "\n",
    "    int_to_vocab = {i: v for v, i in vocab_to_int.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "vocab_to_int_article, int_to_vocab_article = create_lookup_tables([x.lower() for x in articles])\n",
    "vocab_to_int_title, int_to_vocab_title = create_lookup_tables([x.lower() for x in titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    source_id_text = [[source_vocab_to_int[word] for word in sentence.split()] for sentence in source_text.split('\\n')]\n",
    "    target_id_text = [[target_vocab_to_int[word] for word in sentence.split()]+[target_vocab_to_int['<E>']] for sentence in target_text.split('\\n')]\n",
    "    \n",
    "    return source_id_text, target_id_text\n",
    "\n",
    "X, y = text_to_ids(articles.lower(), titles.lower(), vocab_to_int_articles, vocab_to_int_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "hidden_units = 400\n",
    "embedding_size = 200\n",
    "n_layers = 1\n",
    "dropout = 0.5\n",
    "n_iters = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_forward_cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "encoder_backward_cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "decoder_cell = tf.contrib.rnn.GRUCell(state_size)\n",
    "\n",
    "encoder_forward_cell = tf.contrib.rnn.DropoutWrapper(encoder_forward_cell, output_keep_prob = (1-dropout))\n",
    "encoder_backward_cell = tf.contrib.rnn.DropoutWrapper(encoder_backward_cell, output_keep_prob = (1-dropout))\n",
    "decoder_cell = tf.contrib.rnn.DropoutWrapper(decoder_cell, output_keep_prob = (1-dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"seq2seq\", dtype=dtype):\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        encoder_embedding = tf.get_variable(\"embedding\", [source_vocab_size, embedding_size],initializer=embedding_init)\n",
    "        encoder_inputs_embedding = tf.nn.embedding_lookup(encoder_embedding, self.encoder_inputs)\n",
    "        encoder_outputs, encoder_states = tf.nn.bidirectional_dynamic_rnn(encoder_forward_cell, encoder_backward_cell, encoder_inputs_embedding, sequence_length=self.encoder_len, dtype=dtype)\n",
    "\n",
    "    with tf.variable_scope(\"init_state\"):\n",
    "        init_state = fc_layer(\n",
    "            tf.concat(encoder_states, 1), state_size)\n",
    "        self.init_state = init_state\n",
    "        self.init_state.set_shape([self.batch_size, state_size])\n",
    "        self.att_states = tf.concat(encoder_outputs, 2)\n",
    "        self.att_states.set_shape([self.batch_size, None, state_size*2])\n",
    "\n",
    "    with tf.variable_scope(\"attention\"):\n",
    "        attention = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            state_size, self.att_states, self.encoder_len)\n",
    "        decoder_cell = tf.contrib.seq2seq.DynamicAttentionWrapper(\n",
    "            decoder_cell, attention, state_size * 2)\n",
    "        wrapper_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(\n",
    "            self.init_state, self.prev_att)\n",
    "\n",
    "    with tf.variable_scope(\"decoder\") as scope:\n",
    "        decoder_emb = tf.get_variable(\"embedding\", [target_vocab_size, embedding_size],initializer=emb_init)\n",
    "        decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, target_vocab_size)\n",
    "        decoder_inputs_emb = tf.nn.embedding_lookup(decoder_emb, self.decoder_inputs)\n",
    "\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(decoder_inputs_emb, self.decoder_len)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, wrapper_state)\n",
    "\n",
    "        outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "        outputs_logits = outputs[0]\n",
    "        self.outputs = outputs_logits\n",
    "\n",
    "        weights = tf.sequence_mask(self.decoder_len, dtype=tf.float32)\n",
    "\n",
    "        loss_t = tf.contrib.seq2seq.sequence_loss(outputs_logits, self.decoder_targets, weights, average_across_timesteps=False, average_across_batch=False)\n",
    "        self.loss = tf.reduce_sum(loss_t) / self.batch_size\n",
    "\n",
    "        params = tf.trainable_variables()\n",
    "        opt = tf.train.AdadeltaOptimizer(self.learning_rate, epsilon=1e-6)\n",
    "        gradients = tf.gradients(self.loss, params)\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient)\n",
    "        self.updates = opt.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    n_batches = int(len(int_text) / (batch_size * seq_length))\n",
    "    inputs = np.array(int_text[: n_batches * batch_size * seq_length])\n",
    "    outputs = np.array(int_text[1: n_batches * batch_size * seq_length + 1])\n",
    "\n",
    "    x = np.split(inputs.reshape(batch_size, -1), n_batches, 1)\n",
    "    y = np.split(outputs.reshape(batch_size, -1), n_batches, 1)\n",
    "\n",
    "    return np.array(list(zip(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        model = create_model(sess, False)\n",
    "        loss = 0.0\n",
    "        current_step = sess.run(model.global_step)\n",
    "\n",
    "        while current_step <= n_iters:\n",
    "            rand = np.random.random_sample()\n",
    "            bucket_id = min([i for i in range(len(train_buckets_scale))\n",
    "                             if train_buckets_scale[i] > rand])\n",
    "\n",
    "            encoder_inputs, decoder_inputs, encoder_len, decoder_len = model.get_batches(train_set, bucket_id)\n",
    "            step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, encoder_len, decoder_len, False, train_writer)\n",
    "            loss += step_loss * batch_size / np.sum(decoder_len)\n",
    "            current_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
